```
shortname: 6/CSAPI
name: API to register & invoke computer services   
type: Standard
status: Raw
editor: Mike Anderson <mike.anderson@dex.sg>
contributors: Kiran K <kiran.karkera@dex.sg> 
```

<!--ts-->

Table of Contents
=================

   * [Table of Contents](#table-of-contents)
   * [Service Invocation](#service-invocation)
      * [Change Process](#change-process)
      * [Language](#language)
      * [Motivation](#motivation)
      * [Application Abstraction](#application-abstraction)
      * [Constraints](#constraints)
      * [Options for a host platformOpti](#options-for-a-host-platform)
      * [Suggested Choice](#suggested-choice)
      * [Specification](#specification)

      
<!--te-->

<a name="service-invocation"></a>
# Service Invocation

The Service Invocation API (**INVOKE**) is a specification for the Ocean Protocol to register and invoke compute jobs.

INVOKE offers a general purpose computational interface

Compute services are defined as services available on the Ocean Network that

* May accept one or more Input parameters (which will typically be data assets to be used or algorithms to be run)
* Typically produce one or more Outputs (which will typically be references to generated data assets)
* Support the provision of proofs by service providers upon service completion (after which tokens in escrow may be released) 

This OEP does not prescribe the exact type of compute services offered. It is open to service provider implementations to define them, providing that they conform with this API specification
This OEP does not cover service discovery.
The OEP is not intended to apply to services where invocation / access is off-chain (e.g. high volume APIs or queue services)

This specification is based on [Ocean Protocol technical whitepaper](https://github.com/oceanprotocol/whitepaper), [3/ARCH](../3/README.md), [4/KEEPER](../4/README.md) and [5/AGENT](../5/README.md).


<a name="change-process"></a>
## Change Process
This document is governed by the [2/COSS](../2/README.md) (COSS).

<a name="language"></a>
## Language
The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in [BCP 14](https://tools.ietf.org/html/bcp14) \[[RFC2119](https://tools.ietf.org/html/rfc2119)\] \[[RFC8174](https://tools.ietf.org/html/rfc8174)\] when, and only when, they appear in all capitals, as shown here.

<a name="motivation"></a>
## Motivation

Ocean network aims to power marketplaces for relevant AI-related data services.
There is a need for a standardised **interface** for the invocation of compute services so that different implementations can be provided and invoked by users of the Ocean Protocol.

Example of data related services that could be offered by Ocean actors:

* A data cleaning service that removes noise from data
* A model training service that returns a trained model given training data
* A model verification service that returns metrics of a model's performance, given a model and a test data set.
* A consent service which filters a dataset by checking each dataset instance (e.g. a single patient's data in a healthcare study) against an external consent registry.
* A notebook hosting service which grants access to a notebook system such as Jupyter, for a fixed or variable unit of time.

It may be observed that these services

- Enable creation of dataset(s)
- Accept input dataset(s) and transform it in some fashion

The Invoke API enables

- provides Ocean users tools to transform data assets registered on the Ocean network.
- facilitates a workflow pipeline of data asset transformations.
- enables provenance tracking by Ocean provenance aware algorithms.

<a name="specification"></a>

## Application Abstraction

From a temporal perspective, the invoke API has the following types of requirements:

- Registration
  - Register the service on Ocean with metadata that declares its service capabilities.
  - Make service artifacts available (e.g. register a Docker instance of Docker hub)
  
- Deployment 
  - Deploy the package from a trusted source (e.g. install from DockerHub)
  
- Invocation
  The API needs to provide the ability to:
  - start the job providing Ocean (or other) inputs, including configuration
  - Query the status of the job
  - Stop the job (while in progress)
  
- Post invocation
  - Enable collection of results/generated outputs
  - Enable registration of generated assets on Ocean and inform the service consumer
  - Offer proof of compute job completion to verifiers
  
- Uninstallation
  - Uninstall the package.
  - Delete any data generated by the job.

![User flow ](./imgs/InvokeService.png)

## Constraints

The execution environment must support the following abstractions:

* The package must have the capability to be installed in 
  - a local machine 
  - on a publisher's cloud 
  - on a third party cloud service
* The install package must not depend on the host container for managing its dependencies. (e.g. Docker installs all the dependencies, including the correct language version and its dependencies)
* The package must be language agnostic (i.e it should not mandate that the invoke job implementation must use a particular language or language version).
* Report failures with sufficient information to aid consumer debugging

### Service Options

* The service may be offered free or for a price
* The service may be offered in trusted mode or trustless mode (backed by Service Execution Agreements) 
* the service must be identified with its asset ID on the Ocean Network
* the service must register its metadata with the OCEAN agent
* the service container can be installed locally (inthe pubilsher machine or cloud)
* may accept configuration options to tune the algorithm/job to be run.
* may register ocean assets generated as a result of the job. the registered assets must be in the name of the service coinsumer
* may return a payload
* may accept a list of ocean assets as inputs to the job  (along with access tokens to consume the asset)
* may accept a data payload as an input
* The unit of measurement could be 
  - a one-shot execution of a job (e.g. a data cleaning job)
  - a cron-like job that can be scheduled at regular intervals
  - a subscribable service which is active for a fixed unit of time (e.g. a notebook service available for 1 hour)
  
## Options for a host platform

| Host platform | Install package | Dependencies managed            | Scaling across machines | Can be installed locally? | Language agnostic?   |
|---------------|-----------------|---------------------------------|-------------------------|---------------------------|----------------------|
| JVM           | jar             | no                              | no                      | yes                       | (only JVM supported) |
| Python        | pip             | yes (partial-needs more inputs) | no                      | yes                       | no                   |
| Docker        | docker image    | yes                             | no                      | yes                       | yes                  |
| Kubernetes    | Helm chart      | yes                             | yes                     | yes                       | yes                  |
| Spark         | jar             | yes                             | yes                     | yes                       | partial              |
|               |                 |                                 |                         |                           |                      |

## Suggested choice

The suggested choice for the initial host platform is Kubernetes, for the following reasons.

* Open standard (CNCF), 36 companies [support it](https://techcrunch.com/2017/11/13/the-cncf-just-got-36-companies-to-agree-to-a-kubernetes-certification-standard/)
* Can be installed on local or cloud hosts
* Unlike Docker (single image), multi-node orchestration is possible.
* Excellent tooling support, both CLI and REST APIs available.
* Package distribution (Helm charts) has an active ecosystem
* It can use Docker images for containerization

### Example of a Kubernetes invokable service

Prerequisites:
* The K8S tools need to be installed, either locally (using Minikube), or in the cloud, using cloud provider specific tools (e.g. [Amazon EKS](https://aws.amazon.com/eks/) for AWS)
* Assumes that the CLI tool `kubectl` will be installed and available.

- Invoke the job with default arguments 

The job configuration is specified in a .yaml file 

`kubectl create -f https://k8s.io/examples/controllers/job.yaml`

## Specification 

The **Service Metadata** information should be managed using an API on the Ocean Agent. The rest of this document defines a specification designed for the Kubernetes environment. 
This API should exposes the following capabilities in the Ocean Agent:

Kubernetes specific note:

* Helm is one of K8s package manager(here's a [list of competitors](https://blog.hasura.io/draft-vs-gitkube-vs-helm-vs-ksonnet-vs-metaparticle-vs-skaffold-f5aa9561f948)), which uses a file named values.yaml to set properties.
* As the name suggests, the configuration is yaml formatted, which is syntactically similar to JSON.

### Registering a new Service

Registering a service 

* is the same process as registering a new asset with an Ocean Agent.
* uses the same metadata as described in OEP8. In addition to the [regular metadata](https://github.com/oceanprotocol/OEPs/tree/master/8#base-attributes) it must specify the following:

```json
{ "other" : "metadata",
  "type"  : "algorithm",
  "links" : [ {"name" : "My algorithm",
               "type" : "Helm chart",
               "url" : "https://github.com/helm/charts/tree/master/stable/my-algorithm"}]
}

```

In the URL of the service, a values.yaml file should be present, with the following fields set:

  - input arguments , either Ocean assets or data payloads
  ```yaml
  inputs:
  # A map of input assets. In the example below, "oceaninputasset" is the name for one of the Ocean assets,
  # any number of Ocean input assets can be provided
    oceaninputasset:
      assetid: "testassetid"
      asseturl: "path/to/asset"
      type: "oceanasset"
      consumptiontoken: "token"
    #A second input which is a data payload, not from Ocean
    payloadinput: 
      asseturl: "path/to/url"
      type: "payload"
  ```
  
  - location of output assets
  ```yaml
  outputs:
    asset1:
      # This file contains the asset ID generated, and registered by the job
      assetdetails: "/path/to/assetdetails"
  ```

### Retire a Service

Retiring a service uses the same method as retiring an asset

### Invoking the service or job

The values.xml file define the number of inputs required. These values can be overridden in the following ways:

- Use `--set` to set each value for an input. See [example](https://github.com/helm/helm/blob/master/docs/charts.md#using-the-cli-with-tags-and-conditions)
- Provide a values file which contains all the inputs. See [example](https://github.com/helm/helm/blob/master/docs/charts.md#values-files)

### Describe the status of the job

`kubectl describe my-job`

### Get the result of a job

<work in progress>

### Delete a job

`kubectl delete my-job`

## License

This OEP is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.

This OEP is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with this program; if not, see http://www.gnu.org/licenses.

